{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c4986e-5544-479b-a382-fa63a70042cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.image as mpimg\n",
    "import nltk\n",
    "from flax import nnx\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b189abd-cea9-4f2d-a26d-66227d2f9ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hannahb./nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a97f9d-f007-496e-9c70-22bed9850b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trials(trials_path):\n",
    "    trials = []\n",
    "\n",
    "    with open(trials_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            trial = json.loads(line)\n",
    "    \n",
    "            triplet = trial.get(\"triplet\", None)\n",
    "            context = trial.get(\"context\", None)\n",
    "            choice = trial.get(\"choice\", None)\n",
    "    \n",
    "            trials.append({\n",
    "                \"triplet\": triplet,\n",
    "                \"context\": context,\n",
    "                \"choice\": choice,\n",
    "            })\n",
    "            \n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60444673-d091-4372-b037-d78b9a020c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_feat_dict(features_path):\n",
    "    with open(features_path, \"rb\") as f:\n",
    "        features = pickle.load(f)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c965b2a-9552-4b73-a867-861012c6c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_cls_dict(labels_path):\n",
    "    df = pd.read_csv(labels_path)\n",
    "    df[\"Label\"] = df[\"PredictionString\"].str.split().str[0]\n",
    "    \n",
    "    images = [image_id + \".JPEG\" for image_id in list(df[\"ImageId\"])]\n",
    "    classes = list(df[\"Label\"])\n",
    "\n",
    "    img_cls_dict = dict(zip(images,classes))\n",
    "\n",
    "    return img_cls_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab969a1-dc60-41ec-bb6c-171c24728270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_animal(wordnet_id):\n",
    "    synset = wn.synset_from_pos_and_offset(\n",
    "        pos=wordnet_id[0], \n",
    "        offset=int(wordnet_id[1:])\n",
    "    )\n",
    "    animal = wn.synset(\"animal.n.01\")\n",
    "    return animal in synset.closure(lambda s: s.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f5a9812-c61f-478d-8797-9fa5343ba698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clothing(wordnet_id):\n",
    "    synset = wn.synset_from_pos_and_offset(\n",
    "        pos=wordnet_id[0], \n",
    "        offset=int(wordnet_id[1:])\n",
    "    )\n",
    "    clothing = wn.synset(\"clothing.n.01\")\n",
    "    return clothing in synset.closure(lambda s: s.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "923866d9-1f1b-443a-9126-738c899c9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_container(wordnet_id):\n",
    "    synset = wn.synset_from_pos_and_offset(\n",
    "        pos=wordnet_id[0], \n",
    "        offset=int(wordnet_id[1:])\n",
    "    )\n",
    "    container = wn.synset(\"container.n.01\")\n",
    "    return container in synset.closure(lambda s: s.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ad1811-c01d-4cad-887d-72726ced7f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_food(wordnet_id):\n",
    "    synset = wn.synset_from_pos_and_offset(\n",
    "        pos=wordnet_id[0], \n",
    "        offset=int(wordnet_id[1:])\n",
    "    )\n",
    "    food = wn.synset(\"food.n.01\")\n",
    "    return food in synset.closure(lambda s: s.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e16e294-22ea-499a-8fd3-648644ccabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_furniture(wordnet_id):\n",
    "    synset = wn.synset_from_pos_and_offset(\n",
    "        pos=wordnet_id[0], \n",
    "        offset=int(wordnet_id[1:])\n",
    "    )\n",
    "    furniture = wn.synset(\"furniture.n.01\")\n",
    "    return furniture in synset.closure(lambda s: s.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1f38d65-ac59-4a7e-8d0a-e02221848021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_plant(wordnet_id):\n",
    "    synset = wn.synset_from_pos_and_offset(\n",
    "        pos=wordnet_id[0], \n",
    "        offset=int(wordnet_id[1:])\n",
    "    )\n",
    "    plant = wn.synset(\"plant.n.02\")\n",
    "    return plant in synset.closure(lambda s: s.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "953e4d4f-e610-4e63-b742-a3aff50df9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_vehicle(wordnet_id):\n",
    "    synset = wn.synset_from_pos_and_offset(\n",
    "        pos=wordnet_id[0], \n",
    "        offset=int(wordnet_id[1:])\n",
    "    )\n",
    "    vehicle = wn.synset(\"vehicle.n.01\")\n",
    "    return vehicle in synset.closure(lambda s: s.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "281b8b19-cc35-476e-9d78-8e0db50a2b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repr_feats(img_feat_dict, img_cls_dict):\n",
    "    imgs_by_cls = defaultdict(list)\n",
    "    for img in img_feat_dict:\n",
    "        imgs_by_cls[img_cls_dict[img]].append(img)\n",
    "\n",
    "    cls_means = {\n",
    "        cls: np.mean([img_feat_dict[img] for img in imgs], axis=0)\n",
    "        for cls, imgs in imgs_by_cls.items()\n",
    "    }\n",
    "\n",
    "    feats_norm = {\n",
    "        img: feat / np.linalg.norm(feat)\n",
    "        for img, feat in img_feat_dict.items()\n",
    "    }\n",
    "\n",
    "    cls_repr_feat_dict = {}\n",
    "    for cls, mean in cls_means.items():\n",
    "        mean_norm = mean / np.linalg.norm(mean)\n",
    "\n",
    "        repr_img = max(\n",
    "            imgs_by_cls[cls],\n",
    "            key=lambda img: float(np.dot(feats_norm[img], mean_norm)),\n",
    "        )\n",
    "        cls_repr_feat_dict[cls] = img_feat_dict[repr_img]\n",
    "\n",
    "    classes = list(cls_repr_feat_dict.keys())\n",
    "    superclasses = [\"animal\", \"clothing\", \"container\", \"food\", \"furniture\", \"plant\", \"vehicle\", \"other\"]\n",
    "\n",
    "    cls_to_superclass = {}\n",
    "    for cls in classes:\n",
    "        if is_animal(cls):\n",
    "            superclass = \"animal\"\n",
    "        elif is_clothing(cls):\n",
    "            superclass = \"clothing\"\n",
    "        elif is_container(cls) and not is_vehicle(cls): # some vehicles are also containers\n",
    "            superclass = \"container\"\n",
    "        elif is_food(cls):\n",
    "            superclass = \"food\"\n",
    "        elif is_furniture(cls):\n",
    "            superclass = \"furniture\"\n",
    "        elif is_plant(cls):\n",
    "            superclass = \"plant\"\n",
    "        elif is_vehicle(cls):\n",
    "            superclass = \"vehicle\"\n",
    "        else:\n",
    "            superclass = \"other\"\n",
    "        cls_to_superclass[cls] = superclass\n",
    "\n",
    "    sum_len_group = 0\n",
    "    \n",
    "    classes_sorted = []\n",
    "    for superclass in superclasses:\n",
    "        group = [cls for cls in classes if cls_to_superclass[cls] == superclass]\n",
    "        group.sort()\n",
    "        classes_sorted.extend(group)\n",
    "        \n",
    "        print(f\"{superclass}: {sum_len_group}-{sum_len_group+len(group)}\")\n",
    "        sum_len_group += len(group)\n",
    "\n",
    "    repr_feats = np.stack([cls_repr_feat_dict[cls] for cls in classes_sorted], axis=0)\n",
    "    superclasses_sorted = [cls_to_superclass[cls] for cls in classes_sorted]\n",
    "\n",
    "    return repr_feats, cls_repr_feat_dict, superclasses_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58d99462-0ebe-4040-a88f-124de8ddc474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model file does not exist: {model_path}\")\n",
    "\n",
    "    try:\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model: {e}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2adc2c83-0e8c-4f7b-b666-192438c3e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_independent_feats(independent_model, feats):\n",
    "    independent_feats = independent_model.P(feats)\n",
    "    \n",
    "    independent_feats_norm = jnp.linalg.norm(independent_feats, axis=-1, keepdims=True) + 1e-8\n",
    "    independent_feats = independent_feats / independent_feats_norm\n",
    "    \n",
    "    return independent_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc898daa-cdf4-4d64-8136-fa9cb3e798ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor_feats(anchor_model, context_feat, feats):\n",
    "    anchor_feats = anchor_model.P(feats)\n",
    "    anchor_feats = anchor_feats / (jnp.linalg.norm(anchor_feats, axis=-1, keepdims=True) + 1e-8)\n",
    "\n",
    "    B_flat = anchor_model.B_network(context_feat)\n",
    "    B = B_flat.reshape(B_flat.shape[:-1] + (anchor_model.rank, anchor_model.embedding_dim))\n",
    "\n",
    "    anchor_feats = jnp.einsum('...kd,...td->...tk', B, anchor_feats)\n",
    "\n",
    "    return anchor_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96e2a261-0fab-484c-abed-07afc60b57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_choice(model, feats):\n",
    "    f1 = feats[..., 0, :]\n",
    "    f2 = feats[..., 1, :]\n",
    "    f3 = feats[..., 2, :]\n",
    "\n",
    "    sims = jnp.stack(\n",
    "        [\n",
    "            jnp.sum(f2 * f3, axis=-1),\n",
    "            jnp.sum(f1 * f3, axis=-1),\n",
    "            jnp.sum(f1 * f2, axis=-1),\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    preds = nnx.softmax(model.temperature * sims, axis=-1)\n",
    "    choice = jnp.argmax(preds, axis=-1)\n",
    "    \n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93ad473c-7c3e-4d50-a924-b089a7f0e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _visualize_trial_on_axes(\n",
    "    axes, \n",
    "    images_path,\n",
    "    context,\n",
    "    triplet,\n",
    "    choice,\n",
    "    independent_choice,\n",
    "    anchor_choice\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize the trial (context + 3 triplet images) on a provided axes.\n",
    "    \"\"\"\n",
    "    paths = [\n",
    "        os.path.join(images_path, context),\n",
    "        os.path.join(images_path, triplet[0]),\n",
    "        os.path.join(images_path, triplet[1]),\n",
    "        os.path.join(images_path, triplet[2]),\n",
    "    ]\n",
    "    images = [mpimg.imread(p) for p in paths]\n",
    "\n",
    "    # Context title\n",
    "    axes[0].set_title(\"Context\", fontsize=11)\n",
    "\n",
    "    # Build labels for the three choices\n",
    "    labels = [[] for _ in range(3)]\n",
    "    if choice in (0, 1, 2):\n",
    "        labels[choice].append(\"Human\")\n",
    "    if independent_choice in (0, 1, 2):\n",
    "        labels[independent_choice].append(\"Independent\")\n",
    "    if anchor_choice in (0, 1, 2):\n",
    "        labels[anchor_choice].append(\"Anchor\")\n",
    "\n",
    "    for j in range(3):\n",
    "        axes[j + 1].set_title(\"\\n\".join(labels[j]), fontsize=11)\n",
    "\n",
    "    # Show images aligned to the top\n",
    "    for ax, img in zip(axes, images):\n",
    "        ax.imshow(img)\n",
    "        ax.set_anchor(\"N\")\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Add colored frames around the 3 triplet images\n",
    "    colors=(\"red\", \"green\", \"blue\")\n",
    "    \n",
    "    for ax, color in zip(axes[1:], colors):\n",
    "        rect = patches.Rectangle(\n",
    "            (0, 0), 1, 1,\n",
    "            transform=ax.transAxes,\n",
    "            fill=False,\n",
    "            edgecolor=color,\n",
    "            linewidth=6,\n",
    "            clip_on=False\n",
    "        )\n",
    "        ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89c54bf2-4a5b-464c-85e9-27d2a1272dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trial(\n",
    "    idx,\n",
    "    images_path,\n",
    "    context,\n",
    "    triplet,\n",
    "    choice,\n",
    "    independent_choice,\n",
    "    anchor_choice\n",
    "):\n",
    "    \"\"\"\n",
    "    Standalone version.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(12, 3), constrained_layout=True)\n",
    "    fig.suptitle(f\"Trial {idx}\", fontsize=14)\n",
    "    \n",
    "    _visualize_trial_on_axes(\n",
    "        axes,\n",
    "        images_path,\n",
    "        context,\n",
    "        triplet,\n",
    "        choice,\n",
    "        independent_choice,\n",
    "        anchor_choice\n",
    "    )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a66d2f3d-6608-45c8-93e1-953402df6a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _visualize_rsm_on_axes(\n",
    "    axes,\n",
    "    independent_repr_feats,\n",
    "    anchor_repr_feats,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize Independent/Anchor RSMs on provided axes.\n",
    "    \"\"\"\n",
    "    independent_RSM = independent_repr_feats @ independent_repr_feats.T\n",
    "    anchor_RSM = anchor_repr_feats @ anchor_repr_feats.T\n",
    "\n",
    "    im0 = axes[0].imshow(independent_RSM, origin=\"lower\")\n",
    "    axes[0].set_title(\"Independent RSM\")\n",
    "\n",
    "    im1 = axes[1].imshow(anchor_RSM, origin=\"lower\")\n",
    "    axes[1].set_title(\"Anchor RSM\")\n",
    "\n",
    "    fig = axes[0].figure\n",
    "    fig.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "    fig.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    return im0, im1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "271391b2-806d-4633-a804-5b4049905464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_rsm(independent_repr_feats, anchor_repr_feats):\n",
    "    \"\"\"\n",
    "    Standalone version.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4), constrained_layout=True)\n",
    "    \n",
    "    _visualize_rsm_on_axes(\n",
    "        axes,\n",
    "        independent_repr_feats,\n",
    "        anchor_repr_feats\n",
    "    )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69735af3-5430-446f-b290-c354af5533cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_pca(X):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (N, D)\n",
    "        Data matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Y : ndarray, shape (N, 2)\n",
    "        2D embedding.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(\"X must be a 2D array.\")\n",
    "\n",
    "    # Gram matrix\n",
    "    K = X @ X.T\n",
    "\n",
    "    # Double-centering\n",
    "    N = X.shape[0]\n",
    "    J = np.eye(N) - np.ones((N, N)) / N\n",
    "    Kc = J @ K @ J\n",
    "\n",
    "    # Eigen-decomposition\n",
    "    eigvals, eigvecs = np.linalg.eigh(Kc)\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[idx]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "\n",
    "    # 2D embedding\n",
    "    lam = np.maximum(eigvals[:2], 0.0)\n",
    "    Y = eigvecs[:, :2] * np.sqrt(lam)\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a08cd81-617a-4640-90bb-59909b309a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_pca(\n",
    "    ax, \n",
    "    Y, \n",
    "    n_base,\n",
    "    triplet,\n",
    "    title,\n",
    "    superclasses\n",
    "):\n",
    "    superclass_to_color = {\n",
    "        \"animal\": \"tab:blue\",\n",
    "        \"clothing\": \"tab:orange\",\n",
    "        \"container\": \"tab:purple\",\n",
    "        \"food\": \"tab:brown\",\n",
    "        \"furniture\": \"tab:pink\",\n",
    "        \"plant\": \"tab:green\",\n",
    "        \"vehicle\": \"tab:red\",\n",
    "        \"other\": \"tab:gray\",\n",
    "    }\n",
    "\n",
    "    base_colors = [superclass_to_color[s] for s in superclasses]\n",
    "\n",
    "    ax.scatter(\n",
    "        Y[:n_base, 0],\n",
    "        Y[:n_base, 1],\n",
    "        c=base_colors,\n",
    "        s=15,\n",
    "        alpha=0.6\n",
    "    )\n",
    "\n",
    "    triplet_colors = [\"red\", \"green\", \"blue\"]\n",
    "    for i in range(len(triplet)):\n",
    "        ax.scatter(\n",
    "            Y[n_base + i, 0],\n",
    "            Y[n_base + i, 1],\n",
    "            c=triplet_colors[i],\n",
    "            s=80\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"PC 1\")\n",
    "    ax.set_ylabel(\"PC 2\")\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "552a21c6-4818-4fb8-9a52-e26b5e201e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _visualize_pca_on_axes(\n",
    "    axes,\n",
    "    independent_repr_feats,\n",
    "    independent_triplet_feats,\n",
    "    anchor_repr_feats,\n",
    "    anchor_triplet_feats,\n",
    "    triplet,\n",
    "    superclasses\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize independent/anchor PCA on provided axes.\n",
    "    \"\"\"\n",
    "    X_ind = np.asarray(independent_repr_feats, dtype=float)\n",
    "    T_ind = np.asarray(independent_triplet_feats, dtype=float)\n",
    "    X_anc = np.asarray(anchor_repr_feats, dtype=float)\n",
    "    T_anc = np.asarray(anchor_triplet_feats, dtype=float)\n",
    "\n",
    "    if X_ind.ndim != 2 or T_ind.ndim != 2 or X_anc.ndim != 2 or T_anc.ndim != 2:\n",
    "        raise ValueError(\"All feature inputs must be 2D arrays.\")\n",
    "    if X_ind.shape[1] != T_ind.shape[1]:\n",
    "        raise ValueError(\"independent_repr_feats and independent_triplet_feats must have the same dimensionality.\")\n",
    "    if X_anc.shape[1] != T_anc.shape[1]:\n",
    "        raise ValueError(\"anchor_repr_feats and anchor_triplet_feats must have the same dimensionality.\")\n",
    "    if len(triplet) != T_ind.shape[0] or len(triplet) != T_anc.shape[0]:\n",
    "        raise ValueError(\"Length of triplet must match the number of triplet feature rows for both inputs.\")\n",
    "\n",
    "    X_all_ind = np.vstack([X_ind, T_ind])\n",
    "    X_all_anc = np.vstack([X_anc, T_anc])\n",
    "    \n",
    "    Y_ind = _compute_pca(X_all_ind)\n",
    "    Y_anc = _compute_pca(X_all_anc)\n",
    "\n",
    "    _plot_pca(\n",
    "        axes[0],\n",
    "        Y_ind,\n",
    "        n_base=X_ind.shape[0],\n",
    "        triplet=triplet,\n",
    "        title=f\"Independent (PCA)\",\n",
    "        superclasses=superclasses\n",
    "    )\n",
    "    _plot_pca(\n",
    "        axes[1],\n",
    "        Y_anc,\n",
    "        n_base=X_anc.shape[0],\n",
    "        triplet=triplet,\n",
    "        title=f\"Anchor (PCA)\",\n",
    "        superclasses=superclasses\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f79e289e-f5ab-49e9-8152-0d556afccfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pca(\n",
    "    independent_repr_feats,\n",
    "    independent_triplet_feats,\n",
    "    anchor_repr_feats,\n",
    "    anchor_triplet_feats,\n",
    "    triplet,\n",
    "    superclasses\n",
    "):\n",
    "    \"\"\"\n",
    "    Standalone version.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6), constrained_layout=True)\n",
    "    \n",
    "    _visualize_pca_on_axes(\n",
    "        axes,\n",
    "        independent_repr_feats,\n",
    "        independent_triplet_feats,\n",
    "        anchor_repr_feats,\n",
    "        anchor_triplet_feats,\n",
    "        triplet,\n",
    "        superclasses\n",
    "    )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91d24493-91c6-4dd7-b18b-9203b485259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trial_rsm_pca(\n",
    "    idx,\n",
    "    images_path,\n",
    "    context,\n",
    "    triplet,\n",
    "    choice,\n",
    "    independent_choice,\n",
    "    anchor_choice,\n",
    "    independent_repr_feats,\n",
    "    anchor_repr_feats,\n",
    "    independent_triplet_feats,\n",
    "    anchor_triplet_feats,\n",
    "    superclasses\n",
    "):\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8), constrained_layout=True)\n",
    "    fig.suptitle(f\"Trial {idx}\", fontsize=14)\n",
    "\n",
    "    _visualize_trial_on_axes(\n",
    "        axes[0, :],\n",
    "        images_path,\n",
    "        context,\n",
    "        triplet,\n",
    "        choice,\n",
    "        independent_choice,\n",
    "        anchor_choice\n",
    "    )\n",
    "\n",
    "    _visualize_rsm_on_axes(\n",
    "        axes[1, 0:2],\n",
    "        independent_repr_feats,\n",
    "        anchor_repr_feats\n",
    "    )\n",
    "\n",
    "    _visualize_pca_on_axes(\n",
    "        axes[1, 2:4],\n",
    "        independent_repr_feats,\n",
    "        independent_triplet_feats,\n",
    "        anchor_repr_feats,\n",
    "        anchor_triplet_feats,\n",
    "        triplet,\n",
    "        superclasses\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0785e848-bca6-4c33-b1af-6a2265ed6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_preserved(T: np.ndarray, Y: np.ndarray) -> bool:\n",
    "    # pairwise dot products for the triplet\n",
    "    dots = np.array([\n",
    "        T[0] @ T[1],\n",
    "        T[0] @ T[2],\n",
    "        T[1] @ T[2],\n",
    "    ])\n",
    "\n",
    "    # pairwise Euclidean distances for the last 3 embeddings (triplet)\n",
    "    triplet = Y[-3:]\n",
    "    dists = np.array([\n",
    "        np.linalg.norm(triplet[0] - triplet[1]),\n",
    "        np.linalg.norm(triplet[0] - triplet[2]),\n",
    "        np.linalg.norm(triplet[1] - triplet[2]),\n",
    "    ])\n",
    "\n",
    "    # higher dot product = closer, lower distance = closer\n",
    "    return np.array_equal(np.argsort(-dots), np.argsort(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47798a92-c140-49c9-8b55-905e3442126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idxs(\n",
    "    trials_path = \"/home/space/datasets/context_project/data/bretts/behavioural_data/triplets_test.jsonl\",\n",
    "    features_path = \"/home/space/datasets/context_project/data/bretts/feature_vectors/DINOv2-B-alignet/features.pkl\",\n",
    "    labels_path = \"LOC_val_solution.csv\",\n",
    "    independent_model_path = \"/home/space/datasets/context_project/models/\" + \"rare-valley-2178\" + \".pkl\",\n",
    "    anchor_model_path = \"/home/space/datasets/context_project/models/\" + \"sparkling-violet-2008\" + \".pkl\",\n",
    "    images_path = \"/home/space/datasets/imagenet/2012/val_set_unlabeled/all_classes/\"\n",
    "):\n",
    "    trials = get_trials(trials_path) \n",
    "\n",
    "    img_feat_dict = get_img_feat_dict(features_path)\n",
    "    img_cls_dict = get_img_cls_dict(labels_path)\n",
    "\n",
    "    repr_feats, cls_repr_feat_dict = get_repr_feats(img_feat_dict, img_cls_dict)\n",
    "\n",
    "    independent_model = get_model(independent_model_path)\n",
    "    anchor_model = get_model(anchor_model_path)\n",
    "    \n",
    "    T = len(trials)\n",
    "    D = next(iter(img_feat_dict.values())).shape[0]\n",
    "\n",
    "    contexts = np.empty((T, D), dtype=np.float32)\n",
    "    triplets = np.empty((T, 3, D), dtype=np.float32)\n",
    "    choices = np.empty(T, dtype=np.int64)\n",
    "\n",
    "    contexts_repr = np.empty((T, D), dtype=np.float32)\n",
    "    triplets_repr = np.empty((T, 3, D), dtype=np.float32)\n",
    "\n",
    "    for i, trial in enumerate(trials):\n",
    "        context = trial[\"context\"]\n",
    "        triplet = trial[\"triplet\"]\n",
    "        choice = trial[\"choice\"]\n",
    "        \n",
    "        contexts[i] = img_feat_dict[context]\n",
    "        triplets[i] = np.stack([img_feat_dict[img] for img in triplet])\n",
    "        choices[i] = choice\n",
    "        \n",
    "        contexts_repr[i] = cls_repr_feat_dict[img_cls_dict[context]]\n",
    "        triplets_repr[i] = np.stack([cls_repr_feat_dict[img_cls_dict[img]] for img in triplet])\n",
    "\n",
    "    independent_triplets = get_independent_feats(independent_model, triplets)\n",
    "    anchor_triplets = get_anchor_feats(anchor_model, contexts, triplets)\n",
    "    \n",
    "    independent_choices = get_choice(independent_model, independent_triplets)\n",
    "    anchor_choices = get_choice(anchor_model, anchor_triplets)\n",
    "\n",
    "    # Filter for trials where anchor is correct and independent is incorrect\n",
    "    mask_1 = np.array((choices == anchor_choices) & (choices != independent_choices))\n",
    "    print(mask_1.mean(), mask_1.sum())\n",
    "\n",
    "    independent_triplets_repr = get_independent_feats(independent_model, triplets_repr)\n",
    "    anchor_triplets_repr = get_anchor_feats(anchor_model, contexts_repr, triplets_repr)\n",
    "    \n",
    "    independent_choices_repr = get_choice(independent_model, independent_triplets_repr)\n",
    "    anchor_choices_repr = get_choice(anchor_model, anchor_triplets_repr)\n",
    "\n",
    "    # Filter for trials where class representatives yield the same result\n",
    "    mask_2 = np.array((independent_choices == independent_choices_repr) & (anchor_choices == anchor_choices_repr))\n",
    "    print(mask_2.mean(), mask_2.sum())\n",
    "\n",
    "    mask = mask_1 & mask_2\n",
    "    print(mask.mean(), mask.sum())\n",
    "\n",
    "\n",
    "    # Filter for samples where order is preserved by MDS\n",
    "    i = 0\n",
    "    mask_sum = mask.sum()\n",
    "\n",
    "    independent_repr_feats = get_independent_feats(independent_model, repr_feats)\n",
    "    \n",
    "    for idx, trial in enumerate(trials):\n",
    "        if mask[idx]:\n",
    "            if i % 100 == 0 and i != 0:\n",
    "                print(f\"{i}/{mask_sum}\")\n",
    "            i += 1\n",
    "            \n",
    "            anchor_repr_feats = get_anchor_feats(anchor_model, contexts[idx], repr_feats)\n",
    "\n",
    "            independent_triplet_feats = independent_triplets[idx]\n",
    "            anchor_triplet_feats = anchor_triplets[idx]\n",
    "            \n",
    "            X_ind = np.asarray(independent_repr_feats, dtype=float)\n",
    "            T_ind = np.asarray(independent_triplet_feats, dtype=float)\n",
    "            X_anc = np.asarray(anchor_repr_feats, dtype=float)\n",
    "            T_anc = np.asarray(anchor_triplet_feats, dtype=float)\n",
    "            \n",
    "            X_all_ind = np.vstack([X_ind, T_ind])\n",
    "            X_all_anc = np.vstack([X_anc, T_anc])\n",
    "            \n",
    "            Y_ind = _compute_pca(X_all_ind)\n",
    "            Y_anc = _compute_pca(X_all_anc)\n",
    "\n",
    "            independent_ranking_preserved = ranking_preserved(T_ind, Y_ind)\n",
    "            anchor_ranking_preserved = ranking_preserved(T_anc, Y_anc)\n",
    "    \n",
    "            if not independent_ranking_preserved or not anchor_ranking_preserved:\n",
    "                mask[idx] = 0\n",
    "    print(f\"{mask_sum}/{mask_sum}\")\n",
    "    print(mask.mean(), mask.sum())\n",
    "\n",
    "    idxs = np.where(mask)[0]\n",
    "    \n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d56d58ff-1434-483a-be79-11bb9cc6f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(\n",
    "    idxs,\n",
    "    trials_path = \"/home/space/datasets/context_project/data/bretts/behavioural_data/triplets_test.jsonl\",\n",
    "    features_path = \"/home/space/datasets/context_project/data/bretts/feature_vectors/DINOv2-B-alignet/features.pkl\",\n",
    "    labels_path = \"LOC_val_solution.csv\",\n",
    "    independent_model_path = \"/home/space/datasets/context_project/models/\" + \"rare-valley-2178\" + \".pkl\",\n",
    "    anchor_model_path = \"/home/space/datasets/context_project/models/\" + \"sparkling-violet-2008\" + \".pkl\",\n",
    "    images_path = \"/home/space/datasets/imagenet/2012/val_set_unlabeled/all_classes/\"\n",
    "):\n",
    "    trials = get_trials(trials_path) \n",
    "\n",
    "    img_feat_dict = get_img_feat_dict(features_path)\n",
    "    img_cls_dict = get_img_cls_dict(labels_path)\n",
    "    \n",
    "    repr_feats, _, superclasses = get_repr_feats(img_feat_dict, img_cls_dict)\n",
    "\n",
    "    independent_model = get_model(independent_model_path)\n",
    "    anchor_model = get_model(anchor_model_path)\n",
    "    \n",
    "    independent_repr_feats = get_independent_feats(independent_model, repr_feats)\n",
    "    \n",
    "    for idx in idxs:\n",
    "        trial = trials[idx]\n",
    "    \n",
    "        context = trial[\"context\"]\n",
    "        triplet = trial[\"triplet\"]\n",
    "        choice = trial[\"choice\"]\n",
    "    \n",
    "        context_feat = img_feat_dict[context]\n",
    "        triplet_feats = np.stack([img_feat_dict[img] for img in triplet])\n",
    "    \n",
    "        independent_triplet_feats = get_independent_feats(independent_model, triplet_feats)\n",
    "        independent_choice = get_choice(independent_model, independent_triplet_feats)\n",
    "\n",
    "        anchor_repr_feats = get_anchor_feats(anchor_model, context_feat, repr_feats)\n",
    "        anchor_triplet_feats = get_anchor_feats(anchor_model, context_feat, triplet_feats)\n",
    "        anchor_choice = get_choice(anchor_model, anchor_triplet_feats)\n",
    "        \n",
    "        visualize_trial_rsm_pca(\n",
    "            idx,\n",
    "            images_path,\n",
    "            context,\n",
    "            triplet,\n",
    "            choice,\n",
    "            independent_choice,\n",
    "            anchor_choice,\n",
    "            independent_repr_feats,\n",
    "            anchor_repr_feats,\n",
    "            independent_triplet_feats,\n",
    "            anchor_triplet_feats,\n",
    "            superclasses\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f234a09-e3b9-4c53-9b34-9fc4d8c6db4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/space/datasets/context_project/data/bretts/behavioural_data/triplets_test.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m15615\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mvisualize\u001b[39m\u001b[34m(idxs, trials_path, features_path, labels_path, independent_model_path, anchor_model_path, images_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisualize\u001b[39m(\n\u001b[32m      2\u001b[39m     idxs,\n\u001b[32m      3\u001b[39m     trials_path = \u001b[33m\"\u001b[39m\u001b[33m/home/space/datasets/context_project/data/bretts/behavioural_data/triplets_test.jsonl\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     images_path = \u001b[33m\"\u001b[39m\u001b[33m/home/space/datasets/imagenet/2012/val_set_unlabeled/all_classes/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     trials = \u001b[43mget_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrials_path\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     12\u001b[39m     img_feat_dict = get_img_feat_dict(features_path)\n\u001b[32m     13\u001b[39m     img_cls_dict = get_img_cls_dict(labels_path)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mget_trials\u001b[39m\u001b[34m(trials_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_trials\u001b[39m(trials_path):\n\u001b[32m      2\u001b[39m     trials = []\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrials_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[32m      6\u001b[39m             trial = json.loads(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/ml/lib/python3.11/site-packages/IPython/core/interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/space/datasets/context_project/data/bretts/behavioural_data/triplets_test.jsonl'"
     ]
    }
   ],
   "source": [
    "visualize([15615])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da0602-9418-4bfe-8797-fc4e09147b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
